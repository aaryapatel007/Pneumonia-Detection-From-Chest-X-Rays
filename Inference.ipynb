{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import model_from_json, load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.resnet import ResNet50 \n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "from skimage.transform import rescale, resize, downscale_local_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_model():\n",
    "    \n",
    "    model = VGG16(include_top=False, weights='imagenet', input_shape = (512, 512, 3))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def build_my_model():\n",
    "    \n",
    "    # my_model = Sequential()\n",
    "    # ....add your pre-trained model, and then whatever additional layers you think you might\n",
    "    # want for fine-tuning (Flatteen, Dense, Dropout, etc.)\n",
    "    \n",
    "    # if you want to compile your model within this function, consider which layers of your pre-trained model, \n",
    "    # you want to freeze before you compile \n",
    "    \n",
    "    # also make sure you set your optimizer, loss function, and metrics to monitor\n",
    "    \n",
    "    vgg_model = load_pretrained_model()\n",
    "    \n",
    "    for layer in vgg_model.layers[:17]:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    my_model = Sequential()\n",
    "    \n",
    "    my_model.add(vgg_model)\n",
    "    \n",
    "    my_model.add(GlobalAveragePooling2D())\n",
    "    \n",
    "    my_model.add(Dense(256, activation='relu'))\n",
    "    \n",
    "    my_model.add(BatchNormalization())\n",
    "    \n",
    "    my_model.add(Dropout(0.4))\n",
    "    \n",
    "    my_model.add(Dense(64, activation='relu'))\n",
    "    \n",
    "    my_model.add(BatchNormalization())\n",
    "    \n",
    "    my_model.add(Dropout(0.3))\n",
    "    \n",
    "    my_model.add(Dense(32, activation='relu'))\n",
    "    \n",
    "    my_model.add(BatchNormalization())\n",
    "    \n",
    "    my_model.add(Dropout(0.3))\n",
    "    \n",
    "    my_model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return my_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function reads in a .dcm file, checks the important fields for our device, and returns a numpy array\n",
    "# of just the imaging data\n",
    "def check_dicom(filename): \n",
    "    \n",
    "    print('Load file {} ...'.format(filename))\n",
    "    ds = pydicom.dcmread(filename)   \n",
    "    \n",
    "    if(ds.Modality == 'DX' and ds.PatientPosition in ['PA', 'AP'] and (ds.BodyPartExamined == 'CHEST')):\n",
    "        img = ds.pixel_array\n",
    "        return img\n",
    "    \n",
    "    print('Invalid data...')\n",
    "    return None\n",
    "    \n",
    "# This function takes the numpy array output by check_dicom and \n",
    "# runs the appropriate pre-processing needed for our model input\n",
    "def preprocess_image(img, img_size): \n",
    "    \n",
    "    img = resize(img, (img_size[1], img_size[2]))\n",
    "    \n",
    "    proc_img = (img - img.mean()) / img.std()\n",
    "    \n",
    "    return np.resize(proc_img, img_size)\n",
    "\n",
    "# This function loads in our trained model w/ weights and compiles it \n",
    "def load_model(model_path):\n",
    "    \n",
    "    my_model = build_my_model()\n",
    "    my_model.load_weights(model_path)\n",
    "    \n",
    "    return my_model\n",
    "\n",
    "# This function uses our device's threshold parameters to predict whether or not\n",
    "# the image shows the presence of pneumonia using our trained model\n",
    "def predict_image(model, img, thresh): \n",
    "    \n",
    "    prediction = model(img)\n",
    "    \n",
    "    if(prediction > thresh):\n",
    "        prediction = 'Pneumonia'\n",
    "    else:\n",
    "        prediction = \"No Pneumonia\"\n",
    "        \n",
    "    return prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load file test1.dcm ...\n",
      "WARNING:tensorflow:Layer block1_conv1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "No Pneumonia\n",
      "Load file test2.dcm ...\n",
      "No Pneumonia\n",
      "Load file test3.dcm ...\n",
      "No Pneumonia\n",
      "Load file test4.dcm ...\n",
      "Invalid data...\n",
      "Load file test5.dcm ...\n",
      "Invalid data...\n",
      "Load file test6.dcm ...\n",
      "Invalid data...\n"
     ]
    }
   ],
   "source": [
    "test_dicoms = ['test1.dcm','test2.dcm','test3.dcm','test4.dcm','test5.dcm','test6.dcm']\n",
    "\n",
    "model_path = r'xray_class_my_model.h5'\n",
    "\n",
    "IMG_SIZE=(1,512,512,3) # This might be different if you did not use vgg16\n",
    "\n",
    "my_model = load_model(model_path)\n",
    "\n",
    "thresh = 0.25\n",
    "\n",
    "# # use the .dcm files to test your prediction\n",
    "for i in test_dicoms:\n",
    "    \n",
    "    img = check_dicom(i)\n",
    "    \n",
    "    if img is None:\n",
    "        continue\n",
    "    \n",
    "    img_proc = preprocess_image(img, IMG_SIZE)\n",
    "\n",
    "    pred = predict_image(my_model,img_proc,thresh)\n",
    "    print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
